{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download e extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# URL do arquivo compactado\n",
    "url_do_arquivo_zip = 'https://portaldatransparencia.gov.br/download-de-dados/viagens/2023'\n",
    "\n",
    "# Baixando o arquivo compactado\n",
    "resposta = requests.get(url_do_arquivo_zip)\n",
    "\n",
    "# Verificando se a solicitação foi bem-sucedida\n",
    "if resposta.status_code == 200:\n",
    "    # Lendo o conteúdo do arquivo compactado\n",
    "    conteudo_zip = BytesIO(resposta.content)\n",
    "\n",
    "    # Extraindo o conteúdo do arquivo compactado\n",
    "    with zipfile.ZipFile(conteudo_zip, 'r') as zip_ref:\n",
    "        # Local da extracao\n",
    "        zip_ref.extractall('/csv_files')\n",
    "    print(\"Conteúdo extraído com sucesso!\")\n",
    "else:\n",
    "    print(f\"Falha ao baixar o arquivo. Código de status: {resposta.status_code}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura e transformacao dos arquivos .csv em DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_viagem = '../csv_files/2023_Viagem.csv'\n",
    "arquivo_passagem = '../csv_files/2023_Passagem.csv'\n",
    "arquivo_trecho = '../csv_files/2023_Trecho.csv'\n",
    "arquivo_pagamento = '../csv_files/2023_Pagamento.csv'\n",
    "\n",
    "# Carregando os dados do arquivo CSV em um DataFrame do pandas\n",
    "df_viagem = pd.read_csv(arquivo_viagem, sep=';', encoding=\"latin-1\")\n",
    "\n",
    "df_passagem = pd.read_csv(arquivo_passagem, sep=';', encoding=\"latin-1\")\n",
    "\n",
    "df_trecho = pd.read_csv(arquivo_trecho, sep=';', encoding=\"latin-1\")\n",
    "\n",
    "df_pagamento = pd.read_csv(arquivo_pagamento, sep=';', encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados do dataframe Viagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas que não serão utilizadas\n",
    "colunas_to_remove = ['Código do órgão superior', 'Nome do órgão superior', 'Código órgão solicitante', 'Nome órgão solicitante', 'Função', 'Descrição Função', 'Período - Data de início', 'Período - Data de fim', 'Destinos', 'Valor diárias', 'Valor passagens']\n",
    "df_viagem.drop(colunas_to_remove, axis=1, inplace=True)\n",
    "\n",
    "# Tratamento para as colunas com valores monetarios\n",
    "colunas_to_numeric = ['Valor devolução', 'Valor outros gastos']\n",
    "for coluna in colunas_to_numeric:\n",
    "    df_viagem[coluna] = df_viagem[coluna].str.replace(',', '.')\n",
    "    df_viagem[coluna] = df_viagem[coluna].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento dos dados do dataframe Passagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento para as colunas com valores monetarios\n",
    "colunas_to_numeric = [\"Valor da passagem\",\"Taxa de serviço\"]\n",
    "for coluna in colunas_to_numeric:\n",
    "    df_passagem[coluna] = df_passagem[coluna].str.replace(',', '.')\n",
    "    df_passagem[coluna] = df_passagem[coluna].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Removendo colunas desnecessárias\n",
    "colunas_to_remove = ['Número da Proposta (PCDP)']\n",
    "df_passagem.drop(colunas_to_remove, axis=1, inplace=True)\n",
    "\n",
    "# Formatando data e hora para formato correto\n",
    "df_passagem['Data da emissão/compra'] = pd.to_datetime(df_passagem['Data da emissão/compra'], format='%d/%m/%Y', errors='coerce')\n",
    "df_passagem['Hora da emissão/compra'] = pd.to_datetime(df_passagem['Hora da emissão/compra'], format='%H:%M', errors='coerce').dt.time\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento de dados do dataframe Trecho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas desnecessárias\n",
    "colunas_to_remove = ['Número da Proposta (PCDP)']\n",
    "df_trecho.drop(colunas_to_remove, axis=1, inplace=True)\n",
    "\n",
    "# Tratamento dos valores numericos\n",
    "colunas_to_numeric = ['Número Diárias']\n",
    "df_trecho[colunas_to_numeric] = df_trecho[colunas_to_numeric].apply(lambda x: x.str.replace(',', '.'))\n",
    "df_trecho[colunas_to_numeric] = df_trecho[colunas_to_numeric].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Tratamento das datas\n",
    "colunas_to_date = ['Origem - Data', 'Destino - Data']\n",
    "df_trecho[colunas_to_date] = df_trecho[colunas_to_date].apply(pd.to_datetime, format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Conversao para boleano\n",
    "df_trecho['Missao?'] = df_trecho['Missao?'].apply(lambda x: True if x == 'Sim' else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tratamento de dados do dataframe Pagamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo colunas desnecessárias\n",
    "colunas_to_remove = ['Número da Proposta (PCDP)']\n",
    "df_pagamento.drop(colunas_to_remove, axis=1, inplace=True)\n",
    "\n",
    "# Tratamento dos valores numericos\n",
    "colunas_to_numeric = ['Valor']\n",
    "df_pagamento[colunas_to_numeric] = df_pagamento[colunas_to_numeric].apply(lambda x: x.str.replace(',', '.'))\n",
    "df_pagamento[colunas_to_numeric] = df_pagamento[colunas_to_numeric].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserção no banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10892\\2186980315.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf_viagem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TB_VIAGE,'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'append'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdf_passagem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TB_PASSAGEM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'append'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf_trecho\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TB_TRECHO'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'append'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Doc_UFS\\SAD\\projeto_viagens_a_servico\\venv_viagem\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2880\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2881\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2882\u001b[1;33m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2883\u001b[0m         )\n\u001b[0;32m   2884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Doc_UFS\\SAD\\projeto_viagens_a_servico\\venv_viagem\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"'{if_exists}' is not valid for if_exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m     \u001b[0mpandas_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Doc_UFS\\SAD\\projeto_viagens_a_servico\\venv_viagem\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mpandasSQL_builder\u001b[1;34m(con, schema, meta, is_cursor)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[0mcon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_engine_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_sqlalchemy_connectable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSQLDatabase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using URI string without sqlalchemy installed.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Doc_UFS\\SAD\\projeto_viagens_a_servico\\venv_viagem\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, engine, schema, meta)\u001b[0m\n\u001b[0;32m   1408\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetaData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1410\u001b[1;33m             \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMetaData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1412\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got multiple values for argument 'schema'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import urllib.parse as parse\n",
    "\n",
    "engine = create_engine('mssql+pyodbc://sa:%s@localhost/db_viagens_a_servico?driver=ODBC+Driver+17+for+SQL+Server' % parse.quote_plus('Vitor123'))\n",
    "\n",
    "engine.connect()\n",
    "\n",
    "df_viagem.to_sql('TB_VIAGE,', con=engine, if_exists='append', index=False)\n",
    "df_passagem.to_sql('TB_PASSAGEM', con=engine, if_exists='append', index=False)\n",
    "df_trecho.to_sql('TB_TRECHO', con=engine, if_exists='append', index=False)\n",
    "df_pagamento.to_sql('TB_PAGAMENTO', con=engine, if_exists='append', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_viagem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
